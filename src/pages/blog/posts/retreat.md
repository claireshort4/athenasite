---
slug: "/retreat"
title: "Retreat"
---


<img src="../../static/images/retreat/">

“I feel so much more confident about applying for jobs and entering the field, and about making my own contributions with my research. I feel like I actually have a sense of what the field is that I"m entering. I've met a bunch of incredible people, made connections that I'm sure will last, and learned a ton in the process.” - Adelin, Athena Fellow ‘24
“I also feel a little more confident now, because the atmosphere here was really encouraging.” - Jeanne, Athena Fellow ‘24
“Before arriving I didn't have any well-defined plan for the future, my only intention was: study, study and study. And now I feel very motivated, I understand that I am perfectly capable of working in this area and setting up my own business.” - Maria, Athena Retreat Attendee ‘24



## Athena Retreat 2024
In February 2024, Athena fellows, staff, speakers, and coaches spent five days together in Oxford to participate in a compact seminar program. Speakers from organizations including Apollo Research, Aligned AI, PIBBSS, Foresight Institute, GPI, and Cooperative AI Foundation met with mentees to share their research agendas and guidance for the mentees.

Athena fellows also had the opportunities to book office hours with speakers and staff; book sessions with the in-house career coach, Katie Glass; meet with one another for pair debugging and collaboration; and hone presentation skills through delivering their own presentations.

During allotted downtime, fellows enjoyed meditation, painting, hikes through the woods, and exploring Oxford (Windsor, Ashmolean, etc.).

### Retreat Seminar
Primary topics of discussion during the retreat included:
- Fieldmapping of technical approaches and institutions
- AI policy and governance
- Career, funding, and networking opportunities
- How to thrive as a woman or genderqueer individual in AI safety

#### Seminar Presentations

<ul>
    <li><strong>Charlie Griffin:</strong> Aligned AI's approach to alignment and safety research / Succeeding and moving up the ladder as a woman in technical roles</li>
    <li><strong>Rebecca Gorman:</strong> Deceptive alignment: where most of the catastrophic AI risk comes from</li>
    <li><strong>Marius Hobbhahn:</strong> The Shutdown Problem: Incomplete Preferences as a Solution</li>
    <li><strong>Katie Glass:</strong> Self-Promotion Workshop</li>
    <li><strong>Lewis Hammond:</strong> Multi-Agent Risks from Advanced AI</li>
    <li><strong>Elliott Thornley:</strong> Foresight Opportunities</li>
    <li><strong>Niamh Peren:</strong> Shared ontology/abstractions is necessary for alignment/helpfulness/low-impact</li>
    <li><strong>Linda Linsefors:</strong> Governing Agents</li>
    <li><strong>Alan Chan:</strong> Untitled</li>
    <li><strong>Nora Ammann:</strong> Governing Agents</li>
</ul>